<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/TCR.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title publication-title"style="font-size: 50px;" >Test-time Adaptation for Cross-modal Retrieval with Query Shift</h1>
              <div class="is-size-4 publication-authors">
                <!-- Paper authors -->
                      <span class="author-block">Haobin Li,</span>
                      <span class="author-block">Peng Hu,</span>
                      <span class="author-block">Qianjun Zhang,</span>
                      <span class="author-block">
                          <a href="http://pengxi.me/" target="_blank">Xi Peng</a>,</span>
                      <span class="author-block">Xiting Liu,</span>
                      <span class="author-block">Mouxing Yang</span>
                  </div>

                  <!-- <div class="is-size-5 publication-authors">
                    <span class="author-block">Institution Name<br>Conferance name and year</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div> -->
                  <div class="is-size-4 publication-authors">
                      <span class="author-block">
                          <strong style="color: red;">ICLR 2025 (Spotlight)</strong>
                      </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://openreview.net/pdf?id=BmG88rONaU" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/XLearning-SCU/2025-ICLR-TCR" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                  <span class="link-block">
                    <a href="https://www.youtube.com/watch?v=lYK2fCJexPI" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-video"></i>
                    </span>
                    <span>English Video</span>
                </a>
              </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://www.bilibili.com/video/BV1EDRpYzEiL/?vd_source=92c6f2b6158840a7a16b84960ce55d43" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-video"></i>
                  </span>
                  <span>Chinese Video</span>
              </a>
            </span>

                  <span class="link-block">
                    <a href="/static/pdfs/Slides.pdf" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-image"></i>
                    </span>
                    <span>Slides</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Single image section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered" style="max-width: 60%; margin: 0 auto;">
      <!-- Adjust image width -->
      <img src="static/images/fig1.png" alt="Figure 1" style="max-width: 100%; height: auto;"/>
      <!-- Text content with fixed width -->
      <!-- <div class="content has-text-justified" style="max-width: 100%; margin: 0 auto; font-size: 18px">
        Figure 1: (a) <b>Dominant Paradigm</b>: the pre-trained models embrace powerful zero-shot retrieval capacity and could be fine-tuned on domain-specific data for customization, which has emerged as the dominant paradigm for cross-modal retrieval. (b) <b>Query Shift</b>: the performance of the paradigm would be significantly degraded when encountering the query shift problem. On the one hand, collecting sufficient data to tailor the pre-trained models for scarce domains is daunting and even impossible. On the other hand, as the saying goes, “Different strokes for different folks”, even fine-tuned models cannot accommodate all personalized domains. (c) <b>Observations</b>: we study the query shift problem for cross-modal retrieval and reveal the following observations. Namely, query shift not only diminishes the uniformity of the query modality but also amplifies the modality gap between the query and gallery modalities, undermining the well-structured common space inherited from pre-trained models.
      </div> -->
    </div>
  </div>
</section>
<!-- End single image section -->

<div style="max-width: 70%; margin: 0 auto;">
  <p style="font-size: 18px; text-align: justify;">
    Figure 1: (a) <b>Dominant Paradigm</b>: the pre-trained models embrace powerful zero-shot retrieval capacity and could be fine-tuned on domain-specific data for customization, which has emerged as the dominant paradigm for cross-modal retrieval. (b) <b>Query Shift</b>: the performance of the paradigm would be significantly degraded when encountering the query shift problem. On the one hand, collecting sufficient data to tailor the pre-trained models for scarce domains is daunting and even impossible. On the other hand, as the saying goes, “Different strokes for different folks”, even fine-tuned models cannot accommodate all personalized domains. (c) <b>Observations</b>: we study the query shift problem for cross-modal retrieval and reveal the following observations. Namely, query shift not only diminishes the uniformity of the query modality but also amplifies the modality gap between the query and gallery modalities, undermining the well-structured common space inherited from pre-trained models.
  </p>
</div>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified" style="max-width: 100%; margin: 0 auto; font-size: 19px">
          <p>
            The success of most existing cross-modal retrieval methods heavily relies on the assumption that the given queries follow the same distribution of the source domain. However, such an assumption is easily violated in real-world scenarios due to the complexity and diversity of queries, thus leading to the query shift problem. Specifically, query shift refers to the online query stream originating from the domain that follows a different distribution with the source one. In this paper, we observe that query shift would not only diminish the uniformity (namely, within-modality scatter) of the query modality but also amplify the gap between query and gallery modalities. Based on the observations, we propose a novel method dubbed Test-time adaptation for Cross-modal Retrieval (TCR). In brief, TCR employs a novel module to refine the query predictions (namely, retrieval results of the query) and a joint objective to prevent query shift from disturbing the common space, thus achieving online adaptation for the cross-modal retrieval models with query shift. Expensive experiments demonstrate the effectiveness of the proposed TCR against query shift.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Observation Section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">Observation</h1>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered" style="max-width: 50%; margin: 0 auto;">
      <!-- Adjust image width -->
      <img src="static/images/obs.png" alt="Figure obs" style="max-width: 100%; height: auto;"/>
      <!-- Text content with fixed width -->
    </div>
  </div>
</section>

<hr style="margin: 10px 0;">

<!-- Method Section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">Method</h1>
    </div>
  </div>
</section>

<!-- Single image section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered" style="max-width: 75%; margin: 0 auto;">
      <!-- Adjust image width -->
      <img src="static/images/fig2.png" alt="Figure 2" style="max-width: 100%; height: auto;"/>
      <!-- Text content with fixed width -->
      <!-- <div class="content has-text-justified" style="max-width: 100%; margin: 0 auto; font-size: 18px">
        <b>Overview of the proposed TCR</b>. For the given online queries, the modality-specific encoders are employed to project the query and gallery samples into the latent space established by the source model. The obtained query embeddings and gallery embeddings are passed into the query prediction refinement module. In the module, TCR first selects the most similar gallery sample for each query and obtain the query-gallery pairs. After that, the pairs with higher uniformity and lower modality gap are chosen to estimate the filtering threshold of query predictions and modality gap of the source model as the constraints for the adaptation. Finally, three loss functions are employed to achieve robust adaptation for cross-modal retrieval with query shift.
      </div> -->
    </div>
  </div>
</section>
<!-- End single image section -->

<div style="max-width: 70%; margin: 0 auto;">
  <p style="font-size: 18px; text-align: justify;">
    <b>Overview of the proposed TCR</b>. For the given online queries, the modality-specific encoders are employed to project the query and gallery samples into the latent space established by the source model. The obtained query embeddings and gallery embeddings are passed into the query prediction refinement module. In the module, TCR first selects the most similar gallery sample for each query and obtain the query-gallery pairs. After that, the pairs with higher uniformity and lower modality gap are chosen to estimate the filtering threshold of query predictions and modality gap of the source model as the constraints for the adaptation. Finally, three loss functions are employed to achieve robust adaptation for cross-modal retrieval with query shift.
  </p>
</div>

<hr style="margin: 10px 0;">

<!-- Method Section -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">Datasets</h1>
    </div>
  </div>
</section>

<div style="max-width: 70%; margin: 0 auto; font-size: 18px; text-align: justify;">
  <p>
    To investigate the influence of cross-modal retrieval with query shift, we employ the following two settings for extensive evaluations:
  </p>
  <ul>
    <li>
      <b>Query Shift (QS):</b> In this setting, only the queries come from different distributions with the source-domain data. Following <a href="https://arxiv.org/pdf/2212.08044" target="_blank">this work</a>, we introduce 16 types of corruptions to the image modality and 15 types to the text modality across widely-used image-text retrieval datasets, COCO and Flickr. As a result, the COCO-C and Flickr-C benchmarks are constructed, which would result in distribution shifts on either the image or text modalities. To guarantee the controlled study on QS, we first fine-tune the pre-trained model on either the COCO or Flickr dataset, namely, treating them as the source domains. After that, evaluations are conducted on the COCO-C or Flickr-C benchmarks, namely, treating them as the target domain.
    </li>
    <li>
      <b>Query-Gallery Shift (QGS):</b> In this setting, both the query and gallery samples are drawn from distributions different from the source-domain data. To this end, evaluations are directly conducted on the pre-trained model upon several widely-used image-text retrieval datasets from various domains, including Fashion-Gen from the e-commerce domain, CUHK-PEDES and ICFG-PEDES from the person re-identification (ReID) domain, and COCO, Flickr, and Nocaps from the natural image domain. In other words, the source model would encounter distribution shifts on both image and text modalities during adaptation.
    </li>
  </ul>
</div>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered" style="max-width: 50%; margin: 0 auto;">
      <!-- Adjust image width -->
      <img src="static/images/benchmark.png" alt="Figure benchmark" style="max-width: 100%; height: auto;"/>
      <!-- Text content with fixed width -->
      <!-- <div class="content has-text-justified" style="max-width: 100%; margin: 0 auto; font-size: 18px">
        Benchmark the existing TTA methods on cross-modal retrieval with query shift across six datasets and 130 diverse corruptions of varying severity. 
      </div> -->
    </div>
  </div>
</section>

<div style="max-width: 70%; margin: 0 auto;">
  <p style="font-size: 18px; text-align: justify;">
    Notably, we only introduce the corruptions to the query modality in the QS setting, e.g., for image-to-text retrieval, the distribution shifts occur on the image modality. The cases of the 16 image corruptions and 15 text corruptions are visualized in the following figures.
  </p>
</div>

<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered"> <!-- 添加 has-text-centered 使内容居中 -->
      <!-- Carousel -->
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item has-text-centered"> <!-- 添加 has-text-centered 使图片居中 -->
          <!-- Your image here -->
          <img src="static/images/corruption1.png" alt="Corruption 1" style="max-width: 60%; height: auto;"/>
        </div>
        <div class="item has-text-centered"> <!-- 添加 has-text-centered 使图片居中 -->
          <!-- Your image here -->
          <img src="static/images/corruption2.png" alt="Corruption 2" style="max-width: 60%; height: auto;"/>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End image carousel -->


<hr style="margin: 10px 0;">

<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">Comparison</h1>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered" style="max-width: 50%; margin: 0 auto;">
      <!-- Adjust image width -->
      <img src="static/images/exp1.png" alt="Figure exp1" style="max-width: 100%; height: auto;"/>
      <!-- Text content with fixed width -->
      <!-- <div class="content has-text-justified" style="max-width: 100%; margin: 0 auto; font-size: 18px">
        Benchmark the existing TTA methods on cross-modal retrieval with query shift across six datasets and 130 diverse corruptions of varying severity. 
      </div> -->
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">Visualization Result
      </h1>
    </div>
  </div>
</section>

<div style="max-width: 70%; margin: 0 auto;">
  <p style="font-size: 18px; text-align: justify;">
    Here are some visualization results. The proposed method not only enlarge intra-modality uniformity but also ​reduces the modality gap, thereby ​enhancing cross-modal retrieval performance.
  </p>
</div>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered" style="max-width: 75%; margin: 0 auto;">
      <!-- Adjust image width -->
      <img src="static/images/Visualization.png" alt="Figure Visualization" style="max-width: 70%; height: auto;"/>
      <!-- Text content with fixed width -->
      <!-- <div class="content has-text-justified" style="max-width: 100%; margin: 0 auto; font-size: 18px">
        Benchmark the existing TTA methods on cross-modal retrieval with query shift across six datasets and 130 diverse corruptions of varying severity. 
      </div> -->
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered">
      <h1 class="title is-2">Real-word Examples</h1>
    </div>
  </div>
</section>

<div style="max-width: 70%; margin: 0 auto;">
  <p style="font-size: 18px; text-align: justify;">
    We also conducted experiments on ​personalized queries, which is mentioned in the motivation. 
    Specifically, we perform TTA on different needs of users in the ​e-commerce domain.
    The results demonstrate that our approach achieves ​consistent performance improvements in both Image-to-Text or ​Text-to-Image retrieval.
  </p>
</div>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container has-text-centered" style="max-width: 85%; margin: 0 auto;">
      <!-- Adjust image width -->
      <img src="static/images/real.png" alt="Figure real" style="max-width: 70%; height: auto;"/>
      <!-- Text content with fixed width -->
      <!-- <div class="content has-text-justified" style="max-width: 100%; margin: 0 auto; font-size: 18px">
        Benchmark the existing TTA methods on cross-modal retrieval with query shift across six datasets and 130 diverse corruptions of varying severity. 
      </div> -->
    </div>
  </div>
</section>


<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/TCR.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!-- BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{li2025test,
          title={Test-time Adaptation for Cross-modal Retrieval with Query Shift},
          author={Haobin Li, Peng Hu, Qianjun Zhang, Xi Peng, Xiting Liu, Mouxing Yang},
          booktitle={International Conference on Learning Representations},
          year={2025}
        }</code></pre>
  </div>
</section>
<!-- End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
